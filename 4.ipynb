{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.95\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "lst = [10,11,11.2,13,15.5,18,19.8,20,31,33,39.5,42]\n",
    "\n",
    "Q1 = np.quantile(lst, .25)\n",
    "Q3 = np.quantile(lst, .75)\n",
    "IQR = Q3 - Q1\n",
    "print(abs(IQR))\n",
    "# 답 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/facebook.csv')\n",
    "\n",
    "df['target'] = (df['num_loves'] + df['num_wows']) / df['num_reactions']\n",
    "cond1 = (df['target'] > 0.4)\n",
    "cond2 = (df['target'] < 0.5)\n",
    "cond3 = (df['status_type'] == 'video')\n",
    "\n",
    "print(len(df[cond1 & cond2 & cond3]))\n",
    "# 답 90\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "129\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/netflix.csv')\n",
    "df.head()\n",
    "\n",
    "\n",
    "df['date_added']\n",
    "\n",
    "result_df = df[df['date_added'].str.contains('January') & df['date_added'].str.contains('2018')]\n",
    "result_df_uk = result_df[result_df['country'] == 'United Kingdom']\n",
    "print(len(result_df_uk))\n",
    "\n",
    "print(len(result_df['country'] == 'United Kingdom'))\n",
    "\n",
    "print(len(result_df[result_df['country'] == 'United Kingdom']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5014880952380952\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2178 entries, 0 to 2177\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   ID            2178 non-null   int64 \n",
      " 1   Segmentation  2178 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 34.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_train = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/CS_Seg_X_train.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/CS_Seg_X_test.csv')\n",
    "y_train = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/CS_Seg_y_train.csv')\n",
    "\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis = 1)\n",
    "\n",
    "test1 = test.copy()\n",
    "train.drop(columns=['ID'], axis = 1, inplace = True)\n",
    "test.drop(columns=['ID'], axis = 1, inplace = True)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "train['Gender'] = encoder.fit_transform(train['Gender'])\n",
    "test['Gender'] = encoder.transform(test['Gender'])\n",
    "\n",
    "train['Ever_Married'] = encoder.fit_transform(train['Ever_Married'])\n",
    "test['Ever_Married'] = encoder.transform(test['Ever_Married'])\n",
    "\n",
    "train['Graduated'] = encoder.fit_transform(train['Graduated'])\n",
    "test['Graduated'] = encoder.transform(test['Graduated'])\n",
    "\n",
    "train['Profession'] = encoder.fit_transform(train['Profession'])\n",
    "test['Profession'] = encoder.transform(test['Profession'])\n",
    "\n",
    "train['Spending_Score'] = encoder.fit_transform(train['Spending_Score'])\n",
    "test['Spending_Score'] = encoder.transform(test['Spending_Score'])\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "train['Age'] = scaler.fit_transform(train[['Age']])\n",
    "test['Age'] = scaler.transform(test[['Age']])\n",
    "\n",
    "\n",
    "X = train.drop(columns = ['Segmentation'])\n",
    "y = train['Segmentation']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "pred = rfc.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(acc)\n",
    "\n",
    "pred1 = rfc.predict(test)\n",
    "result = pd.DataFrame({'ID' : test1['ID'], 'Segmentation' : pred1})\n",
    "result.to_csv('result4.csv', index=False)\n",
    "\n",
    "d = pd.read_csv('result4.csv')\n",
    "d.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류, Segmentation 예측\n",
    "# ID 빼고 문자형은 라벨 인코더\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ArrowDtype', 'BooleanDtype', 'Categorical', 'CategoricalDtype', 'CategoricalIndex', 'DataFrame', 'DateOffset', 'DatetimeIndex', 'DatetimeTZDtype', 'ExcelFile', 'ExcelWriter', 'Flags', 'Float32Dtype', 'Float64Dtype', 'Grouper', 'HDFStore', 'Index', 'IndexSlice', 'Int16Dtype', 'Int32Dtype', 'Int64Dtype', 'Int8Dtype', 'Interval', 'IntervalDtype', 'IntervalIndex', 'MultiIndex', 'NA', 'NaT', 'NamedAgg', 'Period', 'PeriodDtype', 'PeriodIndex', 'RangeIndex', 'Series', 'SparseDtype', 'StringDtype', 'Timedelta', 'TimedeltaIndex', 'Timestamp', 'UInt16Dtype', 'UInt32Dtype', 'UInt64Dtype', 'UInt8Dtype', '__all__', '__builtins__', '__cached__', '__doc__', '__docformat__', '__file__', '__git_version__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_built_with_meson', '_config', '_is_numpy_dev', '_libs', '_pandas_datetime_CAPI', '_pandas_parser_CAPI', '_testing', '_typing', '_version_meson', 'annotations', 'api', 'array', 'arrays', 'bdate_range', 'compat', 'concat', 'core', 'crosstab', 'cut', 'date_range', 'describe_option', 'errors', 'eval', 'factorize', 'from_dummies', 'get_dummies', 'get_option', 'infer_freq', 'interval_range', 'io', 'isna', 'isnull', 'json_normalize', 'lreshape', 'melt', 'merge', 'merge_asof', 'merge_ordered', 'notna', 'notnull', 'offsets', 'option_context', 'options', 'pandas', 'period_range', 'pivot', 'pivot_table', 'plotting', 'qcut', 'read_clipboard', 'read_csv', 'read_excel', 'read_feather', 'read_fwf', 'read_gbq', 'read_hdf', 'read_html', 'read_json', 'read_orc', 'read_parquet', 'read_pickle', 'read_sas', 'read_spss', 'read_sql', 'read_sql_query', 'read_sql_table', 'read_stata', 'read_table', 'read_xml', 'reset_option', 'set_eng_float_format', 'set_option', 'show_versions', 'test', 'testing', 'timedelta_range', 'to_datetime', 'to_numeric', 'to_pickle', 'to_timedelta', 'tseries', 'unique', 'util', 'value_counts', 'wide_to_long']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(dir(pd))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
